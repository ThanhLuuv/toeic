// H√†m g·ªçi OpenAI API
export async function analyzeWithAI(logText: string): Promise<any> {
  const apiKey = process.env.REACT_APP_API_KEY_OPENAI;
  const endpoint = "https://api.openai.com/v1/chat/completions";

  const messages = [
    {
      role: "system",
      content: "B·∫°n l√† m·ªôt gi√°o vi√™n TOEIC Part 1 th√¥ng minh, chuy√™n ph√¢n t√≠ch l·ªói h·ªçc vi√™n v√† ƒë∆∞a ra b√†i luy·ªán t·∫≠p ch√≠nh x√°c theo t·ª´ng l·ªói."
    },
    {
      role: "user",
      content: `ƒê√¢y l√† c√¢u m√† h·ªçc vi√™n ${logText}

                        == Y√äU C·∫¶U X·ª¨ L√ù ==
                        B·∫°n th·ª±c hi·ªán 2 vi·ªác:

                        1. Ph√¢n t√≠ch l·ªói h·ªçc vi√™n, tr·∫£ v·ªÅ c√°c m·ª•c sau b·∫±ng ti·∫øng vi·ªát:
                        - mainError: l·ªói ch√≠nh ng∆∞·ªùi h·ªçc m·∫Øc ph·∫£i (ng·∫Øn g·ªçn)
                        - reasons: m·∫£ng g·ªìm 2‚Äì3 nguy√™n nh√¢n c·ª• th·ªÉ
                        - solutions: m·∫£ng g·ªìm 2‚Äì3 gi·∫£i ph√°p r√µ r√†ng, ƒë∆°n gi·∫£n ƒë·ªÉ c·∫£i thi·ªán

                        2. Sinh m·ªôt c√¢u luy·ªán t·∫≠p m·ªõi t∆∞∆°ng t·ª± (gi·ªëng c·∫•u tr√∫c ƒë·ªÅ TOEIC Part 1) v·ªõi level t∆∞∆°ng t·ª±, g·ªìm:
                        - imageDescription: m√¥ t·∫£ ·∫£nh chi ti·∫øt b·∫±ng ti·∫øng anh
                        - choices: A/B/C l√† c√¢u m√¥ t·∫£ ·∫£nh (ch·ªâ 1 c√¢u ƒë√∫ng)
                        - choicesVi: b·∫£n d·ªãch ti·∫øng Vi·ªát cho m·ªói c√¢u
                        - correctAnswer: "A" / "B" / "C"
                        - explanation: gi·∫£i th√≠ch v√¨ sao ƒë√°p √°n ƒë√∫ng
                        - traps: m√¥ t·∫£ c√°c b·∫´y ƒë∆∞·ª£c g√†i (v√≠ d·ª•: keywordMisuse, assumption‚Ä¶)

                        == Y√äU C·∫¶U ƒê·∫¶U RA ==
                        Tr·∫£ v·ªÅ duy nh·∫•t 1 object JSON v·ªõi schema sau:

                        {
                        "questionNumber": 6,
                        "analysis": {
                            "correctAnswer": "...",
                            "chosenAnswer": "...",
                            "mainError": "...",
                            "reasons": ["...", "..."],
                            "solutions": ["...", "..."]
                        },
                        "practiceQuestion": {
                            "imageDescription": "...",
                            "choices": {
                            "A": "...",
                            "B": "...",
                            "C": "..."
                            },
                            "choicesVi": {
                            "A": "...",
                            "B": "...",
                            "C": "..."
                            },
                            "correctAnswer": "A" | "B" | "C",
                            "explanation": "...",
                            "traps": "..."
                        }
                        }

                        == DANH M·ª§C B·∫™Y ==
                        trapId            | T√™n               | M√¥ t·∫£  
                        ------------------|-------------------|--------------------------------------  
                        singularPlural    | Singular ‚Üî Plural | Sai s·ªë √≠t / s·ªë nhi·ªÅu  
                        keywordMisuse     | Keyword Misuse    | T·ª´ ƒë√∫ng nh∆∞ng sai h√†nh ƒë·ªông/v·ªã tr√≠  
                        assumption        | Assumption        | M√¥ t·∫£ h√†nh ƒë·ªông kh√¥ng t·ªìn t·∫°i  
                        similarSound      | Similar Sound     | Nh·∫ßm l·∫´n do √¢m gi·ªëng  
                        homophone         | Homophone         | T·ª´ ƒë·ªìng √¢m kh√°c nghƒ©a  
                        misfocus          | Misfocus          | T·∫≠p trung v√†o v·∫≠t ph·ª• kh√¥ng quan tr·ªçng  

                        == QUY T·∫ÆC B·∫ÆT BU·ªòC ==
                        - ƒê√°p √°n ƒë√∫ng l√† ƒë√°p √°n m√¥ t·∫£ ch√≠nh x√°c v·∫≠t th·ªÉ trong ·∫£nh kh√¥ng c·∫ßn ph·∫£i m√¥ t·∫£ ƒë·ªß, ch·ªâ c·∫ßn ƒë√∫ng v·ªÅ v·∫≠t th·ªÉ
                        - ƒê√°p √°n sai l√† ƒë√°p √°n c√≥ c√°c l·ªói sai nh∆∞:
                        + Sai v·ªÅ h√†nh ƒë·ªông
                        + Sai v·ªÅ v·ªã tr√≠/ƒë·ªãa ƒëi·ªÉm
                        + Sai v·ªÅ s·ªë l∆∞·ª£ng
                        + Sai v·ªÅ th·ªùi gian
                        - ƒê√°p √°n sai tr√°nh s·ª≠ d·ª•ng c√°c t·ª´ ƒë·ªìng nghƒ©a ho·∫∑c c√≥ nghƒ©a hao hao gi·ªëng m√¥ t·∫£ v√≠ d·ª• "Vi·∫øt tr√™n quy·ªÉn s·ªë" v√† "Vi·∫øt l√™n gi·∫•y"
                        - Kh√¥ng ƒë∆∞·ª£c ƒë∆∞a c√°c ƒë√°p √°n sai c√≥ t√≠nh kh√¥ng ch·∫Øn ch·∫Øn, v√≠ d·ª• nh∆∞ ·∫¢nh m√¥ t·∫£ l√† "m·ªôt con dao ƒë·∫∑t c·∫°nh m·ªôt gi·ªè hoa qu·∫£", th√¨ kh√¥ng n√™n ghi ƒë√°p √°n sai l√† "Con dao ƒë∆∞·ª£c d√πng th√°i hoa qu·∫£"
                        - Kh√¥ng n√™n ƒë∆∞a c√°c ƒë√°p √°n sai c√≥ t√≠nh chung chung d·∫´n ƒë·∫øn ƒë√°p √°n sai b·ªã ƒë√∫ng, v√≠ d·ª• nh∆∞ M√¥ t·∫£ ·∫£nh l√† "Tr√™n b√†n ƒë∆∞·ª£c b√†y s·ªï, m√°y t√≠nh, n√∫t" ƒë√°p √°n sai l·∫°i ghi l√† "B√†n ƒë∆∞·ª£c b√†y c√°c d·ª•ng c·ª• vƒÉn ph√≤ng" d·∫´n ƒë·∫øn ƒë√°p √°n sai l·∫°i th√†nh ƒë√∫ng

                        == EXAMPLE ==
                        {
                            "questionNumber": 1,
                            "imageDescription": "A black-and-white photo shows a man holding a pen beside a closed laptop on a bare table.",
                            "choices": {
                                "A": "A man is holding a pen beside a closed laptop.",
                                "B": "A man is typing on a laptop.",
                                "C": "A book is on the table."
                            },
                            "choices": {
                                "A": "A man is holding a pen beside a closed laptop.",
                                "B": "A man is typing on a laptop.",
                                "C": "A book is on the table."
                            },
                            "choicesVi": {
                                "A": "M·ªôt ng∆∞·ªùi ƒë√†n √¥ng ƒëang c·∫ßm c√¢y b√∫t b√™n c·∫°nh m√°y t√≠nh x√°ch tay ƒë√£ ƒë√≥ng.",
                                "B": "M·ªôt ng∆∞·ªùi ƒë√†n √¥ng ƒëang g√µ ph√≠m tr√™n m√°y t√≠nh x√°ch tay.",
                                "C": "M·ªôt quy·ªÉn s√°ch n·∫±m tr√™n b√†n."
                            },
                            "correctAnswer": "A",
                            "explanation": "ƒê√°p √°n A ƒë√∫ng v√¨ m√¥ t·∫£ ch√≠nh x√°c h√†nh ƒë·ªông v√† v·ªã tr√≠ c√°c v·∫≠t. B sai v·ªÅ h√†nh ƒë·ªông (typing thay v√¨ holding), C sai v·ªÅ v·∫≠t th·ªÉ (book thay v√¨ pen).",
                            "traps": "D√πng t·ª´ ƒë√∫ng (laptop) nh∆∞ng h√†nh ƒë·ªông sai (typing thay v√¨ holding pen), T·∫≠p trung sai v√†o v·∫≠t kh√¥ng c√≥ (book) thay v√¨ v·∫≠t ch√≠nh (pen)"
                        }

                        == QUY TR√åNH KI·ªÇM TRA NHANH ==
                        - ƒê√°nh d·∫•u ch·ªß th·ªÉ ‚Äì h√†nh ƒë·ªông ‚Äì v·ªã tr√≠ ‚Äì s·ªë l∆∞·ª£ng trong imageDescription.
                        - ƒê·ªëi chi·∫øu t·ª´ng l·ª±a ch·ªçn: ch·ªâ c·∫ßn ƒë√∫ng v·ªõi ·∫£nh, kh√¥ng c·∫ßn ƒë·∫ßy ƒë·ªß so v·ªõi ·∫£nh; C√¢u sai l·ªách ‚â• 1 y·∫øu t·ªë.
                        - Ki·ªÉm tra:
                        + S·ªë t·ª´ (‚â§15)
                        + Kh√¥ng m√†u s·∫Øc/√°nh s√°ng
                        + D√πng ƒë√∫ng th√¨ hi·ªán t·∫°i ti·∫øp di·ªÖn
                        + traps c√≥ ƒë·ªß, gi·∫£i th√≠ch chi ti·∫øt, v√≠ d·ª• b·∫´y ·ªü ƒë√¢y l√† t·ª´ "ship" / É…™p/ ‚Üí con t√†u, gi·ªëng t·ª´ "sheep" / ÉiÀêp/ ‚Üí con c·ª´u
                        - ƒê·∫£m b·∫£o output l√† array JSON n·∫øu nhi·ªÅu c√¢u.
                        - C√¢u t·ª´ tr·∫£ v·ªÅ ph·∫£i ƒë√∫ng ng·ªØ ph√°p n·ªØa
                        - ƒê√°p √°n ƒë√∫ng ph·∫£i random ng·∫´u nhi√™n v·ªÅ A ho·∫∑c B ho·∫∑c C
                        - üëâ CH·ªà TR·∫¢ V·ªÄ JSON, KH√îNG GI·∫¢I TH√çCH, KH√îNG MARKDOWN.
                        `
    }
  ];

  const response = await fetch(endpoint, {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      "Authorization": `Bearer ${apiKey}`
    },
    body: JSON.stringify({
      model: "gpt-4o",
      messages,
      temperature: 1.0,
      max_tokens: 2048,
      top_p: 1.0
    })
  });

  if (!response.ok) {
    if (response.status === 401) {
      throw new Error("OpenAI API key is invalid or expired. Please check your REACT_APP_OPENAI_API_KEY environment variable.");
    }
    throw new Error("OpenAI API error: " + response.statusText);
  }

  const data = await response.json();
  return data.choices[0].message.content;
}

// H√†m t·∫°o ·∫£nh base64 t·ª´ Gemini
export async function generateImageBase64(imageDescription: string): Promise<string> {
  const GEMINI_API_KEY = process.env.REACT_APP_GEMINI_API_KEY;
  console.log(imageDescription);
  const prompt = `${imageDescription}. IMPORTANT: Create a black and white photograph (monochrome, grayscale, no color), realistic and professional quality, suitable for TOEIC test, documentary style. The photo should always depict a Western setting, specifically in England or the USA. The image must look natural and unposed, similar to scenes used in standardized English exams. Do not include any color. The setting, people, and objects should clearly reflect either British or American environments.`;
  const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/imagen-3.0-generate-002:predict?key=${GEMINI_API_KEY}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      instances: { prompt },
      parameters: { sampleCount: 1 }
    })
  });
  const result = await response.json();
  if (result.predictions?.[0]?.bytesBase64Encoded) {
    return `data:image/png;base64,${result.predictions[0].bytesBase64Encoded}`;
  }
  throw new Error('Image generation failed');
}

// H√†m t·∫°o audio base64 t·ª´ Google TTS
export async function generateAudioBase64(practiceQuestion: any): Promise<string> {
  const GOOGLE_TTS_KEY = process.env.REACT_APP_GOOGLE_TTS_KEY || 'AIzaSyAqO6_hgidkr_qandEMZUJlBcAhF3xOsUk';
  function fixPronunciation(text: string) {
    let fixedText = text;
    fixedText = fixedText.replace(/\ba man\b/gi, '<phoneme alphabet="ipa" ph="…ô m√¶n">a man</phoneme>');
    fixedText = fixedText.replace(/\ba woman\b/gi, '<phoneme alphabet="ipa" ph="…ô Ààw äm…ôn">a woman</phoneme>');
    fixedText = fixedText.replace(/\ba person\b/gi, '<phoneme alphabet="ipa" ph="…ô Ààp…úrs…ôn">a person</phoneme>');
    fixedText = fixedText.replace(/\ba boy\b/gi, '<phoneme alphabet="ipa" ph="…ô b…î…™">a boy</phoneme>');
    fixedText = fixedText.replace(/\ba girl\b/gi, '<phoneme alphabet="ipa" ph="…ô …°…úrl">a girl</phoneme>');
    fixedText = fixedText.replace(/\ba dog\b/gi, '<phoneme alphabet="ipa" ph="…ô d…î…°">a dog</phoneme>');
    fixedText = fixedText.replace(/\ba cat\b/gi, '<phoneme alphabet="ipa" ph="…ô k√¶t">a cat</phoneme>');
    fixedText = fixedText.replace(/\ba book\b/gi, '<phoneme alphabet="ipa" ph="…ô b äk">a book</phoneme>');
    fixedText = fixedText.replace(/\ba house\b/gi, '<phoneme alphabet="ipa" ph="…ô ha äs">a house</phoneme>');
    fixedText = fixedText.replace(/\ba car\b/gi, '<phoneme alphabet="ipa" ph="…ô k…ër">a car</phoneme>');
    return fixedText;
  }
  const maleVoice = 'en-US-Wavenet-D';
  const questionNumber = practiceQuestion.questionNumber || 1;
  const questionText = `Look at picture number ${questionNumber}.`;
  const answerA = practiceQuestion.choices.A || '';
  const answerB = practiceQuestion.choices.B || '';
  const answerC = practiceQuestion.choices.C || '';
  const ssmlContent = `
    <speak>
      <voice name="${maleVoice}">
        <prosody rate="slow" pitch="medium">
          ${fixPronunciation(questionText)}
        </prosody>
        <break time="1.2s"/>
        <prosody rate="medium" pitch="medium">
          A. ${fixPronunciation(answerA)}
        </prosody>
        <break time="0.8s"/>
        <prosody rate="medium" pitch="medium">
          B. ${fixPronunciation(answerB)}
        </prosody>
        <break time="0.8s"/>
        <prosody rate="medium" pitch="medium">
          C. ${fixPronunciation(answerC)}
        </prosody>
      </voice>
    </speak>
  `;
  const response = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${GOOGLE_TTS_KEY}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      input: { ssml: ssmlContent },
      voice: { languageCode: 'en-US', name: maleVoice },
      audioConfig: {
        audioEncoding: 'MP3',
        speakingRate: 0.88,
        pitch: 0.0
      }
    })
  });
  const result = await response.json();
  if (result.audioContent) {
    return `data:audio/mp3;base64,${result.audioContent}`;
  }
  throw new Error('Audio generation failed');
} 